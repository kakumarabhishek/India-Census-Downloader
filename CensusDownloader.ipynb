{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import json\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base_url = \"http://censusindia.gov.in/pca/cdb_pca_census/cd_block.html\"\n",
    "base_url = \"http://censusindia.gov.in/pca/cdb_pca_census/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states_page_link = base_url + \"/cd_block.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "states_page = urllib.urlopen(states_page_link)\n",
    "states_soup = BeautifulSoup(states_page.read(), \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# links = [link for link in soup.find_all(\"a\")]\n",
    "links = [link for link in states_soup.find_all(\"a\") if '<a href=\"Houselisting-housing' in str(link)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sep = \"^#^\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andaman and Nicobar Islands UT -> 3\n",
      "Haryana -> 21\n",
      "Nagaland -> 11\n",
      "Andhra Pradesh  -> 23\n",
      "Himachal Pradesh -> 12\n",
      "Odisha -> 30\n",
      "Arunachal Pradesh -> 16\n",
      "Jammu & Kashmir -> 22\n",
      "Puducherry UT -> 2\n",
      "Assam -> 27\n",
      "Jharkhand -> 24\n",
      " Punjab -> 20\n",
      " Bihar -> 38\n",
      "Karnataka -> 30\n",
      "Rajasthan  -> 33\n",
      " Chandigarh UT -> 1\n",
      "Kerala -> 14\n",
      "Sikkim -> 4\n",
      " Chhattisgarh -> 18\n",
      "Lakshadweep UT -> 1\n",
      "Tamil Nadu -> 31\n",
      "Dadra & Nagar Haveli UT -> 1\n",
      "Madhya Pradesh  -> 50\n",
      "Tripura -> 4\n",
      "Daman & Diu UT  -> 2\n",
      "Maharashtra  -> 33\n",
      "Uttar Pradesh -> 71\n",
      "NCT of Delhi -> 7\n",
      "Manipur -> 9\n",
      "Uttarakhand -> 13\n",
      " Goa -> 2\n",
      "Meghalaya -> 7\n",
      " West Bengal -> 18\n",
      "Gujarat -> 26\n",
      "Mizoram -> 8\n"
     ]
    }
   ],
   "source": [
    "with open(\"links.csv\", \"w\") as output:\n",
    "    with open(\"entire_data.csv\", \"w\") as datafile:\n",
    "        for link in links:\n",
    "            output.write(link.contents[0].strip() + \" -> \" + link.attrs[\"href\"] + \"\\n\")\n",
    "#             str = link.contents[0] + sep + link.attrs[\"href\"]\n",
    "            blocks_page_link = base_url + link.attrs[\"href\"]\n",
    "            blocks_page = urllib.urlopen(blocks_page_link)\n",
    "            blocks_soup = BeautifulSoup(blocks_page.read(), \"html.parser\")\n",
    "            file_links = [file_link for file_link in blocks_soup.find_all(\"a\") if ' href=\"PCA CDB' in str(file_link)]\n",
    "            print link.contents[0] + \" -> \" + str(len(file_links))\n",
    "            state_code = ''\n",
    "            for file_link in file_links:\n",
    "                block_name = \" \".join(file_link.contents[0].replace(\"\\r\",\"\").replace(\"\\n\",\"\").split())\n",
    "                output.write(block_name + \" -> \" + file_link.attrs[\"href\"] + '\\n')\n",
    "                datafile.write(link.contents[0].strip() + sep + str(file_link.attrs[\"href\"].split('-')[1][0:2]) + sep + link.attrs[\"href\"] + sep + str(len(file_links)) + sep + block_name + sep+  str(file_link.attrs[\"href\"].split('-')[1]) + sep + file_link.attrs[\"href\"] + \"\\n\")\n",
    "#                 state_code = block_name.split('-')[1][0:2]\n",
    "            output.write('*'*50 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jsonpickle\n",
    "\n",
    "class data(object):\n",
    "    def __init__(self, state_name, block_names):\n",
    "        self.state = state_name\n",
    "        block_list = {}\n",
    "        print block_list\n",
    "        for block in block_names:\n",
    "            block_list.update({'BlockName':block})\n",
    "            print block_list\n",
    "        self.blocks = block_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "point = data(\"Manipur\", [\"Bishnupur\",\"Imphal\",\"Senapati\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jsonpickle.encode(point, unpicklable=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
